{{- $mcp := includeTemplate "mcp.jsonc" . | fromJsonc -}}
{{- $servers := dict -}}
{{- range $key, $value := $mcp.servers -}}
{{- if hasKey $value "command" -}}
{{-   $_ := $value | setValueAtPath "command" (concat (list $value.command) $value.args) -}}
{{-   $_ := $value | deleteValueAtPath "args" -}}
{{- end -}}
{{- if hasKey $value "env" -}}
{{- range $k, $v := $value.env -}}
{{-   $val := $v | replaceAllRegex "\\${" "{env:" -}}
{{-   if ne $v $val -}}
{{-     $_ := $value.env | setValueAtPath $k $val -}}
{{-   end -}}
{{- end -}}
{{-   $_ := $value | setValueAtPath "environment" $value.env -}}
{{-   $_ := $value | deleteValueAtPath "env" -}}
{{- end -}}
{{- if or (not (hasKey $value "type")) (eq $value.type "stdio") -}}
{{-   $_ := $value | setValueAtPath "type" "local" -}}
{{- else if and (hasKey $value "type") (eq $value.type "http") -}}
{{-   $_ := $value | setValueAtPath "type" "remote" -}}
{{- end -}}
{{- $_ := $servers | setValueAtPath $key $value -}}
{{- end -}}
{
  "$schema": "https://opencode.ai/config.json",
  "theme": {{ get . "theme" | default "system" | quote }},
  // "model": "anthropic/claude-sonnet-4-5",
  "autoupdate": false,
  // "instructions": ["CONTRIBUTING.md", "docs/guidelines.md", ".cursor/rules/*.md"],
  "permission": {
    "edit": "deny"
    // "bash": {
    //   "*": "ask",
    //   "git status": "allow"
    // }
  },
  "plugins": [],
  "tools": {
    {{- if lookPath "flux-operator-mcp" | isExecutable }}
    "flux-operator-mcp": false,
    "flux-operator-mcp-ro": true
    {{- end }}
  },
  "agent": {
    "build": {
      "permission": {
        "edit": "ask"
        // "bash": {
        //   "*": "ask",
        //   "git status": "allow",
        //   "git push": "allow"
        // }
      },
      "tools": {
        {{- if lookPath "flux-operator-mcp" | isExecutable }}
        "flux-operator-mcp": true,
        "flux-operator-mcp-ro": false
        {{- end }}
      }
    }
  },
  // "inputs": {{ $mcp.inputs | toJson | indent 2 | trim }},
  "mcp": {{ omit $mcp.servers "flux-operator-mcp-ro" | toPrettyJson | indent 2 | trim }},
  // dict "code-mode" (get $mcp.servers "code-mode") | toPrettyJson | indent 2 | trim
  // "mcp": {
  //   "code-mode": {
  //     "type": "local",
  //     "command": ["npx", "-y", "@utcp/code-mode-mcp"],
  //     "environment": {
  //       "UTCP_CONFIG_FILE": "{env:HOME}/.config/utcp/config.json"
  //     }
  //   }
  // },
  // https://opencode.ai/docs/models/#recommended-models
  {{- if and (eq .osIDLike "darwin") (eq .chezmoi.arch "arm64") }}
  "model": "mlx-community/Llama-3.2-3B-Instruct-4bit",
  {{- end }}
  "provider": {
    {{- if and (eq .osIDLike "darwin") (eq .chezmoi.arch "arm64") }}
    // https://opencode.ai/docs/providers#llamacpp
    // FIXME: Unrecognized schema: {"description":"The call template for the UTCP Manual endpoint."}
    /* "llama.cpp": {
      "npm": "@ai-sdk/openai-compatible",
      "name": "llama-server (local)",
      "options": {
        "baseURL": "http://127.0.0.1:8080/v1"
      },
      "models": {
        // https://github.com/ggml-org/llama.cpp/discussions/15396
        // https://huggingface.co/ggml-org/gpt-oss-20b-GGUF
        // llama-server -hf ggml-org/gpt-oss-20b-GGUF --ctx-size 0 --jinja -ub 2048 -b 2048
        "ggml-org/gpt-oss-20b-GGUF": {
          "name": "gpt-oss-20b-GGUF",
          "limit": {
            "context": 128000,
            "output": 65536
          }
        },
        "qwen3-coder:a3b": {
          "name": "Qwen3-Coder: a3b-30b (local)",
          "limit": {
            "context": 128000,
            "output": 65536
          }
        }
      }
    }, */
    // FIXME: <|channel|>analysis<|message|>[...]
    // <|end|><|start|>assistant<|channel|>final<|message|>[...]
    "mlx-lm": {
      "npm": "@ai-sdk/openai-compatible",
      "name": "MLX LM (local)",
      "options": {
        "baseURL": "http://127.0.0.1:8080/v1"
      },
      "models": {
        "mlx-community/Llama-3.2-3B-Instruct-4bit": {
          "name": "mlx-community/Llama-3.2-3B-Instruct-4bit",
          "reasoning": true,
          "tools": true
        },
        "mlx-community/gpt-oss-20b-mxfp4-q8": {
          "name": "mlx-community/gpt-oss-20b-mxfp4-q8",
          "reasoning": true,
          "tools": true
        },
        "mlx-community/Qwen3-30B-A3B-4bit": {
          "name": "mlx-community/Qwen3-30B-A3B-4bit",
          "reasoning": true,
          "tools": true
        },
        "mlx-community/whisper-large-v3-mlx": {
          "name": "mlx-community/whisper-large-v3-mlx",
          "reasoning": true,
          "tools": true
        },
        "mistralai/Mistral-7B-Instruct-v0.3": {
          "name": "Mistral-7B-Instruct-v0.3",
          "reasoning": true,
          "tools": true
        },
        "lmstudio-community/Qwen3-Coder-30B-A3B-Instruct-MLX-4bit": {
          "name": "lmstudio-community/Qwen3-Coder-30B-A3B-Instruct-MLX-4bit",
          "reasoning": true,
          "tools": true
        }
      }
    },
    // https://opencode.ai/docs/providers#ollama
    "ollama": {
      "npm": "@ai-sdk/openai-compatible",
      "name": "Ollama (local)",
      "options": {
        "baseURL": "http://127.0.0.1:11434/v1"
      },
      "models": {
        "deepseek-r1:8b": {
          "name": "deepseek-r1:8b",
          "reasoning": true,
          "tools": true
        },
        "gpt-oss:20b": {
          "name": "gpt-oss:20b",
          "reasoning": true,
          "tools": true
        },
        // If tool calls arenâ€™t working, try increasing num_ctx in Ollama
        // Start around 16k - 32k
        "llama2": {
          "name": "Llama 2"
        },
        "qwen3": {
          "name": "qwen3",
          "reasoning": true,
          "tools": true
        },
        "qwen3:4b": {
          "name": "qwen3:4b",
          "reasoning": true,
          "tools": true
        },
        "qwen3:8b": {
          "name": "qwen3:8b",
          "reasoning": true,
          "tools": true
        },
        "qwen3:30b": {
          "name": "qwen3:30b",
          "reasoning": true,
          "tools": true
        },
        "qwen3-coder:30b": {
          "name": "qwen3-coder:30b",
          "reasoning": true,
          "tools": true
        }
      }
    },
    {{- end }}
    /* "openai": {
      "models": {
        "gpt-5": {
          "variants": {
            "high": {
              "reasoningEffort": "high",
              "textVerbosity": "low",
              "reasoningSummary": "auto"
            },
            "low": {
              "reasoningEffort": "low",
              "textVerbosity": "low",
              "reasoningSummary": "auto"
            }
          }
        }
      }
    },
    "anthropic": {
      "models": {
        "claude-sonnet-4-5-20250929": {
          "options": {
            "thinking": {
              "type": "enabled",
              "budgetTokens": 16000
            }
          }
        }
      }
    } */
  },
}
